{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark import SparkContext\n",
    "import time\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson similarity between i and j\n",
    "sim_cache = {} #sim_cache\n",
    "def calSim(bid1,bid2):\n",
    "    # find avg rate for each item--all rated, not co-rated\n",
    "    avg_rate_1 = hist_bid_avg_rate[bid1]\n",
    "    avg_rate_2 = hist_bid_avg_rate[bid2]\n",
    "    user_list_1 = hist_bid_uids_info_dict[bid1]\n",
    "    user_list_2 = hist_bid_uids_info_dict[bid2]\n",
    "    # find users both rated i and j\n",
    "    co_rate_users = set(user_list_1).intersection(set(user_list_2))\n",
    "    # calculate (rate-avg_rate) for each user on i and j\n",
    "    nor_rates = []\n",
    "    for  co_rate_user in co_rate_users:\n",
    "        nor_rate_1 = hist_bid_uid_tuple_rate[tuple([bid1,co_rate_user])]-avg_rate_1\n",
    "        nor_rate_2 = hist_bid_uid_tuple_rate[tuple([bid2,co_rate_user])]-avg_rate_2\n",
    "        nor_rates.append([nor_rate_1,nor_rate_2])\n",
    "    # calculate Pearson similarity\n",
    "    nmr = sum([rate[0]*rate[1] for rate in nor_rates])\n",
    "    dnm = math.sqrt(sum([rate[0]**2 for rate in nor_rates]))*math.sqrt(sum([rate[1]**2 for rate in nor_rates]))\n",
    "    if dnm != 0:\n",
    "        sim = nmr/dnm\n",
    "    else:\n",
    "        sim = 0\n",
    "    pair = tuple(sorted([bid1,bid2]))\n",
    "    if pair not in sim_cache:\n",
    "        sim_cache[pair] = sim\n",
    "    return sim\n",
    "\n",
    "def predict(bid_to_pred,test_bid_uids_info_dict):\n",
    "    # [[uid,bid,pred_rate],...]\n",
    "    res = [] \n",
    "    # new bid, use all users rated this bid and rate=3.0 to build item profile\n",
    "    if bid_to_pred not in hist_bids:\n",
    "        # res = [[uid,bid_to_pred,3.0] for uid in test_bid_uids_info_dict[bid_to_pred]]\n",
    "        # or use avg_rate of this user to fill latter\n",
    "        res = [[uid,bid_to_pred,hist_uid_avg_rate[uid]] for uid in test_bid_uids_info_dict[bid_to_pred]]\n",
    "        return res\n",
    "    users_to_pred = test_bid_uids_info_dict[bid_to_pred]\n",
    "    for user in users_to_pred:\n",
    "        rate_sim = []\n",
    "        # new user, use rate=3.0 to build item profile\n",
    "        if user not in hist_uids:\n",
    "            # res.append([user,bid_to_pred,3.0])\n",
    "            # or use avg_rate of this bid to fill latter\n",
    "            res.append([user,bid_to_pred,hist_bid_avg_rate[bid_to_pred]])\n",
    "            continue\n",
    "        # bid and user both have historical data\n",
    "        # if this user only rated bid_to_pred before, use historical data\n",
    "        if hist_uid_bids_info_dict[user]==[bid_to_pred]:\n",
    "            res.append([user,bid_to_pred,hist_bid_uid_tuple_rate[(user,bid_to_pred)]])\n",
    "            continue\n",
    "        # find possible neighbor/bid\n",
    "        possible_nbors = set(hist_uid_bids_info_dict[user])-set(bid_to_pred)\n",
    "        # find co-rated user of bid_to_pred/i and possible_nbor\n",
    "        for possible_nbor in possible_nbors:\n",
    "            co_rate_users = set(hist_bid_uids_info_dict[bid_to_pred]).intersection(set(hist_bid_uids_info_dict[possible_nbor]))\n",
    "            if not co_rate_users:\n",
    "                continue\n",
    "            else:\n",
    "            # calculate sim \n",
    "                # if alreadey calculated\n",
    "                pair = tuple(sorted([bid_to_pred,possible_nbor]))\n",
    "                if pair in sim_cache:\n",
    "                    sim = sim_cache[pair]\n",
    "                else:\n",
    "                    sim = calSim(bid_to_pred,possible_nbor)\n",
    "                rate_sim.append([hist_bid_uid_tuple_rate[(possible_nbor,user)],sim])    \n",
    "        # select top n neighbors\n",
    "        rate_sim.sort(key=lambda x: x[1],reverse=True)\n",
    "        n = min(20,len(rate_sim))\n",
    "        top_nbor_info = rate_sim[:n]\n",
    "        nmr = sum([info[0]*info[1] for info in top_nbor_info])\n",
    "        dnm = sum([abs(info[1]) for info in top_nbor_info])\n",
    "        # predict\n",
    "        if dnm != 0:\n",
    "            rate_pred = 0.1*nmr/dnm +0.5*hist_bid_avg_rate[bid_to_pred]+0.4*hist_uid_avg_rate[user]\n",
    "            rate_pred = min(5.0,max(0.0,rate_pred))\n",
    "        else:\n",
    "            rate_pred = (hist_bid_avg_rate[bid_to_pred]+hist_uid_avg_rate[user])/2\n",
    "        res.append([user,bid_to_pred,rate_pred])\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task2_1.py <input_file_path> <test_file_path> <output_file_path>\n",
    "# input_path = sys.argv[1]\n",
    "# test_path = sys.argv[2]\n",
    "# output_path = sys.argv[3]\n",
    "input_path = \"../data/input/yelp_train.csv\"\n",
    "test_path = \"../data/input/yelp_val.csv\"\n",
    "output_path = \"../data/output/task2_1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/notre/opt/anaconda3/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "23/03/20 12:15:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/03/20 12:15:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "s_time = time.time()\n",
    "sc = SparkContext(\"local[*]\",appName=\"task2_1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item-based CF recommendation system with Pearson similarity\n",
    "# step\n",
    "# Pearson similarity between i and j\n",
    "    # calculate avg rate for each item--all rated, not co-rated\n",
    "    # find users both rated i and j\n",
    "    # calculate (rate-avg_rate) for each user on i and j\n",
    "# select items with highest similarity as neighbors\n",
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read train data and train and get basic info\n",
    "# split one row into (uid,bid,star)\n",
    "train_data = sc.textFile(input_path)\n",
    "head = train_data.first()\n",
    "train_data = train_data.filter(lambda x: x!=head) #exclude the first line of name\n",
    "hist_uid_bid_rate = train_data.map(lambda x: x.split(\",\")).map(lambda x: (x[0],x[1],float(x[2])))\n",
    "# combine bid of the same uid into a list and remove the duplicates\n",
    "# (uid,[bid,bid,...])\n",
    "hist_uid_bids = hist_uid_bid_rate.map(lambda x: (x[0],[x[1]])).reduceByKey(lambda x,y: x+y).mapValues(lambda x: [*set(x)])\n",
    "# {uid:['bid,bid,...]}, find neighbors\n",
    "hist_uid_bids_info_dict = hist_uid_bids.collectAsMap()\n",
    "hist_uids = list(hist_uid_bids_info_dict.keys())\n",
    "# (bid,[uid,uid,...])\n",
    "hist_bid_uids = hist_uid_bid_rate.map(lambda x: (x[1],[x[0]])).reduceByKey(lambda x,y: x+y).mapValues(lambda x: [*set(x)])\n",
    "# {bid:['uid,uid,...]}, find co-rated users\n",
    "hist_bid_uids_info_dict  = hist_bid_uids.collectAsMap()\n",
    "hist_bids = list(hist_bid_uids_info_dict.keys())\n",
    "# {(bid,uid):score}\n",
    "hist_bid_uid_tuple_rate = hist_uid_bid_rate.map(lambda x: ((x[1],x[0]),x[2])).collectAsMap()\n",
    "# avg rate for each item--all rated, not co-rated\n",
    "# {uid:avg_star}\n",
    "hist_uid_avg_rate = hist_uid_bid_rate.map(lambda x: (x[0],x[2])).groupByKey().map(lambda x: (x[0],sum(list(x[1]))/len(list(x[1])))).collectAsMap()\n",
    "# {bid:avg_star}\n",
    "hist_bid_avg_rate = hist_uid_bid_rate.map(lambda x: (x[1],x[2])).groupByKey().map(lambda x: (x[0],sum(list(x[1]))/len(list(x[1])))).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data and train and get basic info\n",
    "test_data = sc.textFile(test_path)\n",
    "test_head = test_data.first()\n",
    "test_data = test_data.filter(lambda x: x!=test_head) #exclude the first line of name\n",
    "# (bid,[uid,uid,...])\n",
    "bid_uids_to_pred = test_data.map(lambda x: x.split(\",\")).map(lambda x: (x[1],[x[0]])).reduceByKey(lambda x,y: x+y).mapValues(lambda x: [*set(x)])\n",
    "# {bid:['uid,uid,...],...}\n",
    "test_bid_uids_info_dict = bid_uids_to_pred.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "after_pred = bid_uids_to_pred.map(lambda x: predict(x[0],test_bid_uids_info_dict)).flatMap(lambda x: x)\n",
    "res = after_pred.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 69.53733587265015\n"
     ]
    }
   ],
   "source": [
    "# less than 130 second\n",
    "e_time = time.time()\n",
    "duration = e_time-s_time\n",
    "print(\"Duration:\",duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv, header: user_id, business_id, similarity\n",
    "with open(output_path,\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"user_id\", \"business_id\", \"similarity\"])\n",
    "    for i in res:\n",
    "        # print(i)\n",
    "        writer.writerow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 1.0490843578388245\n",
      "rmse 1.0490843578388231\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE < 1.09\n",
    "# ((uid,bid),rate)\n",
    "# truth = test_data.map(lambda x: x.split(\",\")).map(lambda x: ((x[0],x[1]),float(x[2])))\n",
    "# my_res = after_pred.map(lambda x: ((x[0],x[1]),x[2]))\n",
    "# RMSE = my_res.join(truth).map(lambda x: (x[1][0]-x[1][1])**2).reduce(lambda x, y: x+y)\n",
    "# print(\"rmse\",math.sqrt(RMSE/my_res.count()))\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import pandas as pd\n",
    "# truth = pd.read_csv(test_path)\n",
    "# res = pd.read_csv(output_path)\n",
    "# merged = truth.merge(res,on=[\"user_id\",\"business_id\"])\n",
    "# print(\"rmse\",mean_squared_error(merged[\"stars\"],merged[\"similarity\"],squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export PYSPARK_PYTHON=python3.6                                                                                  \n",
    "#export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64  \n",
    "#/opt/spark/spark-3.1.2-bin-hadoop3.2/bin/spark-submit --executor-memory 4G --driver-memory 4G task2_1.py\n",
    "# \"../resource/asnlib/publicdata/yelp_train.csv\"\n",
    "# \"../resource/asnlib/publicdata/yelp_val.csv\"\n",
    "# \"./task2_1.csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "db928fd0c57d8c7a39883c08009f12c1243d97ab72bdd745024349e3e8cdaefe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
