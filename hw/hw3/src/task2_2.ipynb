{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pyspark import SparkContext\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "# from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task2_1.py <folder_path> <test_file_path> <output_file_path>\n",
    "# folder_path = sys.argv[1]\n",
    "# test_path = sys.argv[2]\n",
    "# output_path = sys.argv[3]\n",
    "folder_path = \"../data/input/\"\n",
    "test_path = \"../data/input/yelp_val.csv\"\n",
    "output_path = \"../data/output/task2_2.csv\"\n",
    "\n",
    "train_path = folder_path+\"yelp_train.csv\"\n",
    "user_path = folder_path+\"user.json\"\n",
    "business_path = folder_path+\"business.json\"\n",
    "review_train_path = folder_path+\"review_train.json\"\n",
    "# checkin_path = folder_path+\"checkin.json\"\n",
    "# tip_path = folder_path+\"tip.json\"\n",
    "photo_path = folder_path+\"photo.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/notre/opt/anaconda3/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "23/03/18 18:51:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "s_time = time.time()\n",
    "sc = SparkContext(\"local[*]\",appName=\"task2_2\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model-based CF recommendation system with Pearson similarity\n",
    "# step\n",
    "    # train_data+features join together\n",
    "    # fit model \n",
    "    # select parameters\n",
    "# predict on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPriceRange(attributes,key):\n",
    "    if attributes:\n",
    "        if key in attributes.keys():\n",
    "            return float(attributes.get(key))\n",
    "    return 0\n",
    "\n",
    "# var_rate and photo_cnt may be None\n",
    "def fillInNone(num,default):\n",
    "    if num:\n",
    "        return num\n",
    "    else:\n",
    "        return default\n",
    "    \n",
    "# uid_info: {user_id:(review_count,fans,average_stars,friends,social,var_rate)}\n",
    "# bid_info: {business_id:(stars,review_count,price_range,var_rate,phtot_cnt)}\n",
    "# get and join features together, all inputs are dictionaries\n",
    "def mergrFeatures(df_org,uid_info,bid_info):\n",
    "    col_names = [\"bsn_photo_cnt\",\"bsn_review_cnt\",\"bsn_avg_rate\",\"bsn_var_rate\",\n",
    "                 \"user_fans\",\"user_review_cnt\",\"user_avg_rate\",\"user_var_rate\",\n",
    "                 \"user_friends\",\"user_social\",\"bsn_price_range\"]\n",
    "    # col_names = [\"user_review_cnt\",\"user_fans\",\"user_avg_rate\",\"user_var_rate\",\n",
    "    #              \"user_friends\",\"user_social\",\"bsn_avg_rate\",\"bsn_var_rate\",\n",
    "    #             \"bsn_review_cnt\",\"bsn_price_range\",\"bsn_photo_cnt\"]\n",
    "    user_review_cnt = []\n",
    "    user_fans = []\n",
    "    user_avg_rate = []\n",
    "    user_var_rate = []\n",
    "    user_friends = []\n",
    "    user_social = []\n",
    "    bsn_avg_rate = []\n",
    "    bsn_var_rate = []\n",
    "    bsn_review_cnt = []\n",
    "    bsn_price_range = [ ]\n",
    "    bsn_photo_cnt = []\n",
    "    for uid in df_org[\"user_id\"]:\n",
    "        if uid in uid_info.keys():\n",
    "            user_review_cnt.append(uid_info.get(uid)[0])\n",
    "            user_fans.append(uid_info.get(uid)[1])\n",
    "            user_avg_rate.append(uid_info.get(uid)[2])\n",
    "            user_friends.append(uid_info.get(uid)[3])\n",
    "            user_social.append(uid_info.get(uid)[4])\n",
    "            user_var_rate.append(uid_info.get(uid)[5])\n",
    "        else:\n",
    "            user_review_cnt.append(uid_review_cnt_whole)\n",
    "            user_fans.append(uid_fans_whole)\n",
    "            user_avg_rate.append(uid_avg_rate_whole)\n",
    "            user_friends.append(uid_fri_whole)\n",
    "            user_social.append(uid_social_whole)\n",
    "            user_var_rate.append(0)\n",
    "    for bid in df_org[\"business_id\"]:\n",
    "        if bid in bid_info.keys():\n",
    "            bsn_avg_rate.append(bid_info.get(bid)[0])\n",
    "            bsn_var_rate.append(bid_info.get(bid)[3])\n",
    "            bsn_review_cnt.append(bid_info.get(bid)[1])\n",
    "            bsn_price_range.append(bid_info.get(bid)[2])\n",
    "            bsn_photo_cnt.append(bid_info.get(bid)[4])\n",
    "        else:\n",
    "            bsn_avg_rate.append(bid_avg_rate_whole)\n",
    "            bsn_review_cnt.append(bid_review_cnt_whole)\n",
    "            bsn_price_range.append(bid_price_range_whole)\n",
    "            bsn_var_rate.append(0)\n",
    "            bsn_photo_cnt.append(0)\n",
    "            # bsn_avg_rate.append(3)\n",
    "            # bsn_review_cnt.append(0)\n",
    "            # bsn_price_range.append(0)\n",
    "\n",
    "    for i in col_names:\n",
    "        df_org[i] = locals()[i]\n",
    "    \n",
    "    return df_org\n",
    "\n",
    "# def fixInvalidCols(df):\n",
    "#     for col in df.columns:\n",
    "#         if df[col].dtype == 'object':\n",
    "#             encoder = preprocessing.LabelEncoder()\n",
    "#             encoder.fit(list(df[col].values))\n",
    "#             df[col] = encoder.transform(list(df[col].values))\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and pre_datasets, select features\n",
    "# train_data\n",
    "train_data = sc.textFile(train_path)\n",
    "head = train_data.first()\n",
    "train_data = train_data.filter(lambda x: x!=head) #exclude the first line of name\n",
    "train_uid_bid_rate = train_data.map(lambda x: x.split(\",\")).map(lambda x: (x[0],x[1],float(x[2])))\n",
    "# hist_uids = hist_uid_bid_rate.map(lambda x: x[0]).distinct()\n",
    "# hist_bids = hist_uid_bid_rate.map(lambda x: x[1]).distinct()\n",
    "\n",
    "# user, select: user_id,(review_count,fans,average_stars,friends,useful,funny,cool))\n",
    "user = sc.textFile(user_path).map(lambda x: json.loads(x))\n",
    "user = user.map(lambda x: (x[\"user_id\"],(x[\"review_count\"],x[\"fans\"],x[\"average_stars\"],len(x[\"friends\"].split(\",\")),x[\"useful\"]+x[\"funny\"]+x[\"cool\"])))\n",
    "\n",
    "# business, select: business_id,(stars,review_count,attributes[RestaurantsPriceRange2])) \n",
    "# try to add attributes[OutdoorSeating,RestaurantsReservations,RestaurantsTakeOut] later, True/False\n",
    "business = sc.textFile(business_path).map(lambda x: json.loads(x))\n",
    "business = business.map(lambda x: (x[\"business_id\"],(x[\"stars\"],x[\"review_count\"],getPriceRange(x[\"attributes\"],\"RestaurantsPriceRange2\"))))\n",
    "\n",
    "# review_train, (user_id,business_id,stars)\n",
    "review_train = sc.textFile(review_train_path).map(lambda x: json.loads(x))\n",
    "review_train = review_train.map(lambda x: (x[\"user_id\"],x[\"business_id\"],x[\"stars\"]))\n",
    "\n",
    "# photo, select:business_id,label(['food', 'drink', 'outside', 'inside', 'menu'])\n",
    "photo = sc.textFile(photo_path).map(lambda x: json.loads(x))\n",
    "photo = photo.map(lambda x: (x[\"business_id\"],x[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# aggragation\n",
    "# user, select: user_id,(review_count,fans,average_stars,friends,useful,funny,cool))\n",
    "# review_cnt\n",
    "# if uid not in extra dataset, use the average review_cnt in extra dataset \n",
    "uid_review_cnt_whole = user.map(lambda x: x[1][0]).mean()\n",
    "# fans\n",
    "uid_fans_whole = user.map(lambda x: x[1][1]).mean()\n",
    "# avg_rate\n",
    "uid_avg_rate_whole = user.map(lambda x: x[1][2]).mean()\n",
    "# friends\n",
    "uid_fri_whole = user.map(lambda x: x[1][3]).mean()\n",
    "# (usrful+funny+cool)\n",
    "uid_social_whole = user.map(lambda x: x[1][4]).mean()\n",
    "# var_rate\n",
    "uid_var_rate = review_train.map(lambda x: (x[0],x[2])).groupByKey().mapValues(lambda x: np.var((list(x))))\n",
    "# uid_info: {user_id:(review_count,fans,average_stars,friends,social,var_rate)}\n",
    "uid_info = user.leftOuterJoin(uid_var_rate).map(lambda x: x).map(lambda x: (x[0],x[1][0]+(fillInNone(x[1][1],0),))).collectAsMap()\n",
    "\n",
    "# business, select: business_id,(stars,review_count,attributes[RestaurantsPriceRange2])) \n",
    "# avg_rate\n",
    "bid_avg_rate_whole = business.map(lambda x: x[1][0]).mean()\n",
    "# var_rate\n",
    "bid_var_rate = review_train.map(lambda x: (x[1],x[2])).groupByKey().mapValues(lambda x: np.var((list(x))))\n",
    "# review_cnt\n",
    "bid_review_cnt_whole = business.map(lambda x: x[1][1]).mean()\n",
    "# price_range\n",
    "bid_price_range_whole = business.map(lambda x: x[1][2]).mean()\n",
    "# photo_cnt\n",
    "bid_photo_cnt = photo.filter(lambda x: x[1]!=\"menu\").map(lambda x: (x[0],1)).reduceByKey(lambda x,y:x+y)\n",
    "# bid_info: {business_id:(stars,review_count,price_range,var_rate,phtot_cnt)}\n",
    "bid_info = business.leftOuterJoin(bid_var_rate).map(lambda x: (x[0],x[1][0]+(fillInNone(x[1][1],0),))).\\\n",
    "                    leftOuterJoin(bid_photo_cnt).map(lambda x: (x[0],x[1][0]+(fillInNone(x[1][1],0),))).collectAsMap()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uid_info: {user_id:(review_count,fans,average_stars,friends,social,var_rate)}\n",
    "# uid_info.get(\"QPREECpJrp8Dj3_TK22oqg\")\n",
    "# bid_info: {business_id:(stars,review_count,price_range,var_rate,phtot_cnt)}\n",
    "# bid_info.get(\"ugLqbAvBdRDc-gS4hpslXw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_train_org = pd.DataFrame(train_uid_bid_rate.collect(),columns=[\"user_id\",\"business_id\",\"stars\"])\n",
    "df_train = mergrFeatures(df_train_org,uid_info,bid_info)\n",
    "x_train = df_train.drop([\"user_id\",\"business_id\",\"stars\"],axis=1)\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "# scaler.fit(x_train)\n",
    "# x_train = scaler.transform(x_train)\n",
    "# standarize\n",
    "for col in x_train.columns:\n",
    "    x_train[col] = (x_train[col]-x_train[col].mean())/x_train[col].std()\n",
    "y_train = df_train[\"stars\"]\n",
    "\n",
    "# read test data and train and get basic info\n",
    "test_data = sc.textFile(test_path)\n",
    "test_head = test_data.first()\n",
    "test_data = test_data.filter(lambda x: x!=test_head) #exclude the first line of name\n",
    "uid_bid_to_pred = test_data.map(lambda x: x.split(\",\")).map(lambda x: (x[0],x[1])).collect()\n",
    "df_test_org = pd.DataFrame(uid_bid_to_pred,columns=[\"user_id\",\"business_id\"])\n",
    "df_test = mergrFeatures(df_test_org,uid_info,bid_info)\n",
    "x_test = df_test.drop([\"user_id\",\"business_id\"],axis=1)\n",
    "# x_test = scaler.transform(x_test)\n",
    "for col in x_test.columns:\n",
    "    x_test[col] = (x_test[col]-x_test[col].mean())/x_test[col].std()\n",
    "y_true = test_data.map(lambda x: x.split(\",\")).map(lambda x: float(x[2])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select parameters\n",
    "# xgb_model = xgb.XGBRegressor()\n",
    "# param_grid = {\"alpha\":[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],\n",
    "#             #   \"max_depth\":range(3,10,2),\n",
    "#               \"learning_rate\":[0.05,0.01,0.1]}\n",
    "# grid_search = GridSearchCV(xgb_model,param_grid,cv=5)\n",
    "# grid_search = grid_search.fit(x_train,y_train)\n",
    "# alpha = grid_search.best_params_[\"alpha\"]\n",
    "# learning_rate = grid_search.best_params_[\"learning_rate\"]\n",
    "# print(alpha,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9660015618769402\n",
      "0.9915105289970777\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "alpha= 0.6\n",
    "learning_rate = 0.05\n",
    "xgb_model = xgb.XGBRegressor(alpha=alpha,learning_rate=learning_rate,random_state=0)\n",
    "xgb_model.fit(x_train,y_train)\n",
    "print(mean_squared_error(y_train,xgb_model.predict(x_train),squared=False))\n",
    "\n",
    "# predict\n",
    "y_pred = xgb_model.predict(x_test)\n",
    "output = pd.DataFrame({\"user_id\":[x[0] for x in uid_bid_to_pred],\"business_id\":[x[1] for x in uid_bid_to_pred],\"prediction\": y_pred})\n",
    "# calculate RMSE < 1.00\n",
    "print(mean_squared_error(np.array(y_true),y_pred,squared=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 77.69799828529358\n"
     ]
    }
   ],
   "source": [
    "# less than 100 second\n",
    "e_time = time.time()\n",
    "duration = e_time-s_time\n",
    "print(\"Duration:\",duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv, header: user_id, business_id, prediction\n",
    "output.to_csv(output_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export PYSPARK_PYTHON=python3.6                                                                                  \n",
    "#export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64  \n",
    "#/opt/spark/spark-3.1.2-bin-hadoop3.2/bin/spark-submit --executor-memory 4G --driver-memory 4G task2_2.py\n",
    "# \"../resource/asnlib/publicdata/\"\n",
    "# \"../resource/asnlib/publicdata/yelp_val.csv\"\n",
    "# \"./task2_2.csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "db928fd0c57d8c7a39883c08009f12c1243d97ab72bdd745024349e3e8cdaefe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
